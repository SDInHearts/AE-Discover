name: Scraping Discover Pages

on:
  schedule:
    - cron: "0 0 * * *"  # Runs at midnight every day (adjust to your needs)
  workflow_dispatch:  # Allows manual triggering of the action

jobs:
  scrape:
    runs-on: ubuntu-latest  # Runs the script on the latest Ubuntu

    steps:
    - name: Checkout repository
      uses: actions/checkout@v2  # Checks out your repository

    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: 3.8  # You can change to the version of Python you're using

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt  # Make sure you have a requirements.txt file with dependencies

    - name: Run the scraping script
      run: |
        python scrape.py  # Your scraping script file name

    - name: Commit and push JSON files to GitHub
      run: |
        git config --global user.email "youremail@example.com"  # Your GitHub email
        git config --global user.name "yourusername"  # Your GitHub username
        git add .  # Adds all changes to Git
        git commit -m "Add scraped JSON files"
        git push  # Pushes changes to the repository
