name: Scraping Movies

on:
  schedule:
    - cron: "0 0 * * *"  # Runs at midnight every day
  workflow_dispatch:  # Allows manual execution

jobs:
  scrape:
    runs-on: ubuntu-latest  # Use the latest Ubuntu environment

    steps:
    - name: Checkout repository
      uses: actions/checkout@v2  # Fetch the repository code

    - name: Install Chrome & ChromeDriver
      run: |
        sudo apt-get update
        sudo apt-get install -y wget unzip libnss3 libatk-bridge2.0-0 libgdk-pixbuf2.0-0 libx11-xcb1 libxcomposite1 libxdamage1 libxrandr2 libgbm1 libasound2
        wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb
        sudo dpkg -i google-chrome-stable_current_amd64.deb || sudo apt-get install -f -y
        CHROME_VERSION=$(google-chrome --version | awk '{print $3}')
        wget https://chromedriver.storage.googleapis.com/$CHROME_VERSION/chromedriver_linux64.zip || wget https://chromedriver.storage.googleapis.com/`curl -sS chromedriver.storage.googleapis.com/LATEST_RELEASE`/chromedriver_linux64.zip
        unzip chromedriver_linux64.zip
        sudo mv chromedriver /usr/local/bin/
        sudo chmod +x /usr/local/bin/chromedriver
        google-chrome --version
        chromedriver --version

    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: 3.8
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Run the scraping script
      run: python scrape.py

    - name: Commit and push JSON files
      run: |
        git config --global user.email "rifatahmedsajeeb@gmail.com"
        git config --global user.name "SDInHearts"
        git add page/*.json
        git commit -m "Update scraped movie data" || echo "No changes to commit"
        git push
      continue-on-error: true  # Prevents workflow failure if there's no change
